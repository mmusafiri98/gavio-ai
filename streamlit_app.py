import streamlit as st
import torch
import numpy as np
from PIL import Image
import tempfile
import os
import time
import zipfile
from io import BytesIO

# Configuration de la page
st.set_page_config(
    page_title="üé¨ Text-to-Video Simple",
    page_icon="üé¨",
    layout="wide"
)

# CSS simple
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        color: #4CAF50;
        margin-bottom: 2rem;
    }
    .stButton > button {
        background: linear-gradient(90deg, #4CAF50, #45a049);
        color: white;
        border: none;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

st.markdown('<h1 class="main-header">üé¨ G√©n√©rateur Text-to-Video Simple</h1>', unsafe_allow_html=True)

# Fonction pour charger le mod√®le (simplifi√©e)
@st.cache_resource
def load_simple_model():
    try:
        from diffusers import DiffusionPipeline
        
        with st.spinner("üîÑ Chargement du mod√®le..."):
            model_id = "damo-vilab/text-to-video-ms-1.7b"
            
            pipe = DiffusionPipeline.from_pretrained(
                model_id,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
            )
            
            if torch.cuda.is_available():
                pipe = pipe.to("cuda")
                st.sidebar.success("‚úÖ GPU utilis√©")
            else:
                st.sidebar.info("üíª CPU utilis√©")
                
            return pipe
            
    except Exception as e:
        st.error(f"‚ùå Erreur de chargement: {e}")
        return None

# Interface utilisateur
col1, col2 = st.columns([3, 1])

with col1:
    prompt = st.text_area(
        "üìù D√©crivez votre vid√©o:",
        value="un uomo che corre",
        height=80
    )

with col2:
    num_frames = st.slider("üéûÔ∏è Frames", 8, 24, 16)
    seed = st.number_input("üé≤ Seed", value=42, min_value=0)

# G√©n√©ration
if st.button("üöÄ G√©n√©rer"):
    if prompt.strip():
        pipe = load_simple_model()
        
        if pipe:
            try:
                with st.spinner("üé¨ G√©n√©ration en cours..."):
                    # Configuration
                    generator = torch.manual_seed(seed)
                    
                    # G√©n√©ration
                    with torch.inference_mode():
                        result = pipe(
                            prompt,
                            num_frames=num_frames,
                            generator=generator,
                            num_inference_steps=20,
                            guidance_scale=7.0
                        )
                    
                    # R√©cup√©ration des frames
                    if hasattr(result, 'frames') and result.frames:
                        frames = result.frames[0]
                    else:
                        frames = result if isinstance(result, list) else [result]
                    
                    st.success(f"‚úÖ {len(frames)} frames g√©n√©r√©es!")
                    
                    # Affichage des frames
                    st.markdown("**üñºÔ∏è Frames g√©n√©r√©es:**")
                    
                    # Grille d'affichage
                    cols = st.columns(4)
                    for i, frame in enumerate(frames[:12]):  # Afficher max 12 frames
                        with cols[i % 4]:
                            if isinstance(frame, Image.Image):
                                st.image(frame, caption=f"Frame {i+1}", use_column_width=True)
                            else:
                                st.image(Image.fromarray(frame), caption=f"Frame {i+1}", use_column_width=True)
                    
                    # Cr√©er un ZIP avec toutes les frames
                    zip_buffer = BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
                        for i, frame in enumerate(frames):
                            # Convertir en PIL si n√©cessaire
                            if not isinstance(frame, Image.Image):
                                frame = Image.fromarray(frame)
                            
                            # Sauvegarder dans le ZIP
                            img_buffer = BytesIO()
                            frame.save(img_buffer, format='PNG')
                            zip_file.writestr(f"frame_{i+1:03d}.png", img_buffer.getvalue())
                    
                    zip_buffer.seek(0)
                    
                    # Bouton de t√©l√©chargement
                    st.download_button(
                        label="‚¨áÔ∏è T√©l√©charger toutes les frames (ZIP)",
                        data=zip_buffer.getvalue(),
                        file_name=f"frames_{int(time.time())}.zip",
                        mime="application/zip"
                    )
                    
                    # Instructions pour cr√©er la vid√©o
                    st.markdown("---")
                    st.markdown("**üé¨ Pour cr√©er une vid√©o √† partir des frames:**")
                    st.code("""
# Avec ffmpeg (si install√©)
ffmpeg -r 8 -i frame_%03d.png -vcodec libx264 -pix_fmt yuv420p output.mp4

# Ou avec Python
from PIL import Image
import imageio

frames = []
for i in range(1, num_frames+1):
    img = Image.open(f'frame_{i:03d}.png')
    frames.append(np.array(img))

imageio.mimsave('video.mp4', frames, fps=8)
                    """)
                    
            except Exception as e:
                st.error(f"‚ùå Erreur lors de la g√©n√©ration: {e}")
    else:
        st.warning("‚ö†Ô∏è Veuillez entrer un prompt")

# Informations
st.markdown("---")
st.markdown("""
**‚ÑπÔ∏è Cette version simplifi√©e:**
- G√©n√®re des frames individuelles
- √âvite les probl√®mes de d√©pendances vid√©o
- Permet de t√©l√©charger les frames en ZIP
- Les frames peuvent √™tre assembl√©es en vid√©o s√©par√©ment

**üí° Conseils:**
- Commencez avec 16 frames pour tester
- Utilisez des descriptions d√©taill√©es
- Ajustez le seed pour varier les r√©sultats
""")

# Status syst√®me
with st.expander("üñ•Ô∏è Informations syst√®me"):
    st.write(f"GPU disponible: {'‚úÖ' if torch.cuda.is_available() else '‚ùå'}")
    if torch.cuda.is_available():
        st.write(f"GPU: {torch.cuda.get_device_name()}")
    st.write(f"PyTorch: {torch.__version__}")
